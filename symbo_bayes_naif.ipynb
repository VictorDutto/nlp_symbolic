{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2feebbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e13b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n",
    "    path=\"imdb.npz\",\n",
    "    num_words=None,\n",
    "    skip_top=0,\n",
    "    maxlen=None,\n",
    "    seed=113,\n",
    "    start_char=1,\n",
    "    oov_char=2,\n",
    "    index_from=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b673bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_sentence(review):\n",
    "    word_index = keras.datasets.imdb.get_word_index()\n",
    "    inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "    decoded_sequence = \" \".join(inverted_word_index[i] for i in review)\n",
    "    return decoded_sequence\n",
    "\n",
    "decode_sentence(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c707896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_values'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(word_index.values()))\n",
    "print(type(list(word_index.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8550e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# utilisation de numpy pour verifier que la separation des jeux a ete correctement effectue\n",
    "\n",
    "print(type(x_train))\n",
    "np.array(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369102e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_length(x_train):\n",
    "    res = 0\n",
    "    for l in x_train:\n",
    "        res += len(l)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2f53b94-3e70-4d0d-a6b9-c11a0dcb5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def naive_bayes_classifier_train(x_train, y_train):\n",
    "    \"\"\"\n",
    "    Classificateur Bayesien naif\n",
    "    Inputs: le trainset du dataset imdb\n",
    "    Output: TODO\n",
    "    \"\"\"\n",
    "    # tuple valeur/etiquette dans chaque element de imbd\n",
    "    ndoc = len(x_train)\n",
    "    nbclasses = len(np.unique(y_train))\n",
    "    \n",
    "    logprior = [0] * nbclasses\n",
    "    bigdoc = [[]] * nbclasses\n",
    "    vocabulary = list(keras.datasets.imdb.get_word_index().values())\n",
    "    loglikelyhood = np.ndarray((len(voca), nbclasses))\n",
    "    \n",
    "    for c in range(nbclasses):\n",
    "        nlogdoc = math.log(ndoc)\n",
    "        # array numpy, donc masque\n",
    "        c_class_train = x_train[y_train == c]\n",
    "        nc = len(c_class_train)\n",
    "        logprior[c] = nlogdoc / math.log(nc)\n",
    "        #recuperation des cles sous formes numerisees\n",
    "        occu_voca = np.zeros(len(vocabulary))\n",
    "        for docu in tqdm(c_class_train):\n",
    "            occu_voca = np.add(occu_voca, np.histogram(docu, bins=np.arange(len(voca) + 1))[0])\n",
    "        nb_word_total  = get_total_length(c_class_train)\n",
    "        print(nb_word_total)\n",
    "        for index in tqdm(range(len(vocabulary))):\n",
    "            value = math.log((occu_voca[index] + 1) /\n",
    "                                      (nb_word_total + 1))\n",
    "            loglikelyhood[index, c] = value\n",
    "    return logprior, loglikelyhood, voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a274d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:13<00:00, 912.54it/s]\n",
      "100%|██████████| 88584/88584 [00:00<00:00, 591711.74it/s]\n",
      "  0%|          | 0/12500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2948304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 8653/12500 [00:10<00:04, 863.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-815b552ef2f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mlogprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloglikelyhood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoca\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes_classifier_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-009058cd8205>\u001b[0m in \u001b[0;36mnaive_bayes_classifier_train\u001b[0;34m(x_train, y_train)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moccu_voca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_class_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moccu_voca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moccu_voca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoca\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mnb_word_total\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_total_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_class_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_word_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mcum_n\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbin_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;31m# density overrides the normed keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnot_equal\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(logprior, loglikelyhood, voca) = naive_bayes_classifier_train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d228b19-b05a-4ba2-bce8-a1b28d62b50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.073477326743371, 1.073477326743371],\n",
       " array([[-14.89674099, -14.9206144 ],\n",
       "        [ -5.46317707,  -5.48705048],\n",
       "        [-14.20359381, -14.9206144 ],\n",
       "        ...,\n",
       "        [-14.20359381, -14.9206144 ],\n",
       "        [-14.20359381, -14.9206144 ],\n",
       "        [-14.20359381, -14.22746722]]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logprior, loglikelyhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2963b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(testdoc, logprior, loglikelyhood, C, V):\n",
    "    _sum = [0] * len(C)\n",
    "    for c in range(len(C)):\n",
    "        _sum[c] = logprior[c]\n",
    "        for (i, word) in enumerate(testdoc):\n",
    "            if word in V:\n",
    "                _sum[c] += loglikelyhood[i, c] \n",
    "    return np.argmax(_sum)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c7605e4-8cb7-458d-82c7-9a99c9a79fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = list(inverted_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05c85952-3b9c-4251-bc7d-17b3577808e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_naive_bayes(decode_sentence(x_test[1]), logprior, loglikelyhood, [0, 1], V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34af05db-748a-4e22-86ca-e88b09253828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a808cf-b94c-4362-bd0a-a936ad6b6423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
