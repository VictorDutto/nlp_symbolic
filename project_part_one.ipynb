{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97532498-ca3b-4acb-abc4-3e3df3bccd26",
   "metadata": {},
   "source": [
    "# First Part of Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3f87543d-7238-4882-9b80-2cf69bf48897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011eb56c-8ab5-4d89-bf12-888b07b2f6d6",
   "metadata": {},
   "source": [
    "### Importing IMDB sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f7bb2c3c-97d1-4484-94cf-22c15128b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9f814af5-7439-4ee4-9697-3a57af683b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IMDB DATA\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4d5eec8c-a4dd-4068-aec6-68d322e4cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data  (25000,)\n",
      "train_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "test_data  (25000,)\n",
      "test_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "Maximum value of a word index \n",
      "88586\n",
      "Maximum length num words of review in train \n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data \", x_train.shape)\n",
    "print(\"train_labels \", y_train.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"test_data \", x_test.shape)\n",
    "print(\"test_labels \", y_test.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"Maximum value of a word index \")\n",
    "print(max([max(sequence) for sequence in x_train]))\n",
    "print(\"Maximum length num words of review in train \")\n",
    "print(max([len(sequence) for sequence in x_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d1bf7344-d539-4b00-9444-3328d5bdac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "70cb0ab6-5d49-48a7-aee1-b75dfa5e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ac8ad523-6237-4ba4-bc35-b16872ecaf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d391623-8558-477b-9196-e27486a516d4",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a1ec2171-c26c-46a3-9903-796c750a3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(occurence):\n",
    "    return sum(occurence)/float(len(occurence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5e7cbff8-b4b3-4a18-96b7-a8fcb4076223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the review that are belonging to c class\n",
    "def get_review_from_c(dataset, _class):\n",
    "    L = []\n",
    "    for i in range(len(dataset)):\n",
    "        if (y_train[i] == _class):\n",
    "            L.append(x_train[i])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f61fd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_from_c_opti(x_train, y_train, _class, V):\n",
    "    reviews = x_train[y_train == _class]\n",
    "    \n",
    "    for i in range (len(reviews)):\n",
    "        \n",
    "        # Decode sequence in the dataset\n",
    "        decoded_review = \" \".join(V[i] for i in reviews[i])\n",
    "        reviews[i] = decoded_review\n",
    "        \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "93bc9d88-a2bf-44a8-8905-eb539d417cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_occurence_in_bigdoc(bigdoc, word, V):\n",
    "    count = 0\n",
    "    \n",
    "    for review in bigdoc:\n",
    "        \n",
    "        # Binary naive Bayes ?\n",
    "        if word in review:\n",
    "            count += review.count(word)\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a94e4066-814d-495a-8e32-4e774425890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_word(dataset):\n",
    "    count = 0\n",
    "    for review in dataset:\n",
    "        count += len(review)\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "9b7da432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(dataset):\n",
    "    new_vocab = dict()\n",
    "    for value, key in dataset.items():\n",
    "        if key in [\"the\", \"a\", \"le\", \"la\", \"un\", \"une\"]:\n",
    "            continue\n",
    "        else:\n",
    "            new_vocab[key] = value\n",
    "    return new_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "32ce16d8-45e8-466d-9a4e-7e133757bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(dataset, classes):\n",
    "    V = keras.datasets.imdb.get_word_index()\n",
    "\n",
    "    logPrior = dict()\n",
    "    bigdoc = dict()\n",
    "    \n",
    "    logLikelihood = np.zeros((len(V), len(classes)))\n",
    "    \n",
    "    # Preprocessing \n",
    "    V = remove_stop_words(V)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for _class in classes:\n",
    "        N_doc = len(dataset)\n",
    "        review_from_c = get_reviews_from_c_opti(x_train, y_train, _class, V)\n",
    "        N_c = len(review_from_c)\n",
    "        logPrior[_class] = np.log(N_c / N_doc)\n",
    "        \n",
    "        bigdoc[_class] = review_from_c\n",
    "        sum_occurence = get_number_word(review_from_c)\n",
    "        count = 0\n",
    "        for key, value in tqdm(V.items()):\n",
    "            \n",
    "            count_ = get_number_occurence_in_bigdoc(review_from_c, value, V)\n",
    "            \n",
    "            logLikelihood[key, _class] = np.log((count_ + 1) / (sum_occurence + 1))\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "    return (logPrior, logLikelihood, V)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b75e0f31-ab6f-41f8-bd44-8716f3ac41fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 191/88584 [00:04<35:52, 41.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-324-ec4a002aa140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_naive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-323-8c2e1ffb9f60>\u001b[0m in \u001b[0;36mtrain_naive_bayes\u001b[0;34m(dataset, classes)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mcount_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_number_occurence_in_bigdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_from_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mlogLikelihood\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_class\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum_occurence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-316-795b170e5247>\u001b[0m in \u001b[0;36mget_number_occurence_in_bigdoc\u001b[0;34m(bigdoc, word, V)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Binary naive Bayes ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_naive_bayes(x_train, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "49420147-0127-4a04-901b-ea09f1196685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(testdoc, logPrior, logLikelihood, classes, vocabulary):\n",
    "    _sum = dict()\n",
    "    \n",
    "    for _class in classes:\n",
    "        _sum[_class] = logPrior[_class]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
