{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97532498-ca3b-4acb-abc4-3e3df3bccd26",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f87543d-7238-4882-9b80-2cf69bf48897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011eb56c-8ab5-4d89-bf12-888b07b2f6d6",
   "metadata": {},
   "source": [
    "### Importing IMDB sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bb2c3c-97d1-4484-94cf-22c15128b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f814af5-7439-4ee4-9697-3a57af683b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IMDB DATA\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.imdb.load_data(\n",
    "    path=\"imdb.npz\",\n",
    "    num_words=None,\n",
    "    skip_top=0,\n",
    "    maxlen=None,\n",
    "    seed=113,\n",
    "    start_char=1,\n",
    "    oov_char=2,\n",
    "    index_from=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5eec8c-a4dd-4068-aec6-68d322e4cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data  (25000,)\n",
      "train_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "test_data  (25000,)\n",
      "test_labels  (25000,)\n",
      "____________________________________________________________________________________________________\n",
      "Maximum value of a word index \n",
      "88586\n",
      "Maximum length num words of review in train \n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data \", x_train.shape)\n",
    "print(\"train_labels \", y_train.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"test_data \", x_test.shape)\n",
    "print(\"test_labels \", y_test.shape)\n",
    "print(\"_\"*100)\n",
    "print(\"Maximum value of a word index \")\n",
    "print(max([max(sequence) for sequence in x_train]))\n",
    "print(\"Maximum length num words of review in train \")\n",
    "print(max([len(sequence) for sequence in x_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bf7344-d539-4b00-9444-3328d5bdac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cb0ab6-5d49-48a7-aee1-b75dfa5e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31a9af",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5351241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb30bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_lexicon(path):\n",
    "    data = pd.read_csv(path, sep='\\t', names=[0, 1, 2, 3])\n",
    "    df = pd.DataFrame()\n",
    "    df['token'] = data[0]\n",
    "    df['sentiment'] = data[1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853b85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_no_appear(review) -> int:\n",
    "    if word_index[\"no\"] in review:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755e64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_first_and_second_pro(review) -> int:\n",
    "    count = 0\n",
    "    for word in review:\n",
    "        if word in [word_index['you'], word_index['i'], word_index['yours']]:\n",
    "                    count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b24196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! not found, let's see if we find it in a word\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    word_index['!']\n",
    "except KeyError:\n",
    "    print(\"! not found, let's see if we find it in a word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f10640c",
   "metadata": {},
   "source": [
    "Let's search for all the words finishing with !\n",
    "\n",
    "As it would make no sense that the ! character appears before the end of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e86cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "for key, value in word_index.items():\n",
    "    if key.endswith('!') or key.endswith(\"! \"):\n",
    "        found = True\n",
    "        #displaying the key finishing by ! and its value\n",
    "        print(key, value)\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6d0be",
   "metadata": {},
   "source": [
    "it appears no words ends with ! in the training set\n",
    "\n",
    "Thus, there is no need to check for ! in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d10a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_word_count_in_doc(review):\n",
    "    return np.log(len(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1abdf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lexicon(lexicon, word_index):\n",
    "    # only the int value of the words present in index\n",
    "    filtered_lexicon, i = pd.DataFrame([], columns=['token_int', 'token_string', 'sentiment']), 0\n",
    "    for index in range(lexicon.shape[0]):\n",
    "        token = lexicon['token'][index]\n",
    "        if token in word_index.keys():\n",
    "            mapped_token = word_index[token]\n",
    "            filtered_lexicon.loc[i] = [mapped_token, lexicon.token[index], lexicon.sentiment[index]]\n",
    "            i += 1\n",
    "    return filtered_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6ffbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lexicon(lexicon):\n",
    "    positive_df = lexicon[lexicon.sentiment > 0]\n",
    "    positive_words = positive_df['token_int'].to_numpy().tolist()\n",
    "    negative_df = lexicon[lexicon.sentiment < 0]\n",
    "    negative_words = negative_df['token_int'].to_numpy().tolist()\n",
    "    return positive_words, negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6058e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_words_pos(review, positive_words):\n",
    "    posi = np.isin(positive_words, review)\n",
    "    return sum(posi)\n",
    "\n",
    "def number_of_words_neg(review, negative_words):\n",
    "    nega = np.isin(negative_words, review)\n",
    "    return sum(nega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f8e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoRegression(X_train, y_train):\n",
    "    lexicon = import_lexicon(\"vader_lexicon.txt\")\n",
    "    word_index = keras.datasets.imdb.get_word_index()\n",
    "    lexicon = filter_lexicon(lexicon, word_index)\n",
    "    positive_words, negative_words = split_lexicon(lexicon)\n",
    "    \n",
    "    X_features = []\n",
    "    for review in tqdm(x_train):\n",
    "        #as said earlier, there is no ! characters in word index\n",
    "        #thus it doesnt exist in the review\n",
    "        feature = np.zeros(5)\n",
    "        feature[0] = does_no_appear(review)\n",
    "        feature[1] = count_first_and_second_pro(review)\n",
    "        feature[2] = log_word_count_in_doc(review)\n",
    "        feature[3] = number_of_words_neg(review, negative_words)\n",
    "        feature[4] = number_of_words_pos(review, positive_words)\n",
    "\n",
    "        X_features.append(feature)\n",
    "    return np.asarray(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "848e5082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [03:58<00:00, 104.91it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_features = LoRegression(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "484e87c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35a65246",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c48cdb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [04:03<00:00, 102.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#create X_test using loRegression to have a usable informations\n",
    "X_test_features = LoRegression(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc22a769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5) (25000,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_features)\n",
    "print(X_test_features.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1235a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49396"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c4cbdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.51      0.52      0.52     12500\n",
      "     class 1       0.51      0.49      0.50     12500\n",
      "\n",
      "    accuracy                           0.51     25000\n",
      "   macro avg       0.51      0.51      0.51     25000\n",
      "weighted avg       0.51      0.51      0.51     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bb782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
